% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/gan-trainer.R
\name{adjust_learning_rate}
\alias{adjust_learning_rate}
\title{Adjust Learning Rate}
\usage{
adjust_learning_rate(
  optimizer,
  initial_lr,
  current_epoch,
  total_epochs,
  lr_schedule,
  lr_decay_factor,
  lr_decay_steps
)
}
\arguments{
\item{optimizer}{A torch optimizer object}

\item{initial_lr}{The initial learning rate}

\item{current_epoch}{The current epoch number (1-indexed)}

\item{total_epochs}{Total number of training epochs}

\item{lr_schedule}{The learning rate schedule type}

\item{lr_decay_factor}{Decay factor for step/exponential schedules}

\item{lr_decay_steps}{Epochs between decays for step schedule}
}
\value{
The new learning rate (invisibly). Modifies optimizer in place.
}
\description{
Internal helper function to adjust optimizer learning rates
according to the specified schedule.
}
\keyword{internal}
