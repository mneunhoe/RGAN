% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/dp-gan-trainer.R
\name{dp_gan_trainer}
\alias{dp_gan_trainer}
\title{dp_gan_trainer}
\usage{
dp_gan_trainer(
  data,
  noise_dim = 2,
  noise_distribution = "normal",
  data_type = "tabular",
  generator = NULL,
  discriminator = NULL,
  base_lr = 1e-04,
  target_epsilon = 1,
  target_delta = 1e-05,
  max_grad_norm = 1,
  noise_multiplier = NULL,
  sampling_rate = NULL,
  batch_size = 50,
  epochs = 50,
  plot_progress = FALSE,
  plot_interval = "epoch",
  eval_dropout = FALSE,
  synthetic_examples = 500,
  plot_dimensions = c(1, 2),
  track_loss = FALSE,
  device = "cpu",
  seed = NULL,
  verbose = TRUE
)
}
\arguments{
\item{data}{Input a data set. Needs to be a matrix, array, or torch::torch_tensor.}

\item{noise_dim}{The dimensions of the GAN noise vector z. Defaults to 2.}

\item{noise_distribution}{The noise distribution. Expects a function that samples
from a distribution and returns a torch_tensor. For convenience "normal" and
"uniform" will automatically set a function. Defaults to "normal".}

\item{data_type}{"tabular" or "image", controls the data type, defaults to "tabular".}

\item{generator}{The generator network. Expects a neural network provided as
torch::nn_module. Default is NULL which will create a simple fully connected network.}

\item{discriminator}{The discriminator network. Expects a neural network provided as
torch::nn_module. Default is NULL which will create a simple fully connected network.}

\item{base_lr}{The base learning rate for the optimizers. Default is 0.0001.}

\item{target_epsilon}{Target epsilon for differential privacy. Training will
stop if this budget is exhausted. Defaults to 1.0.}

\item{target_delta}{Target delta for differential privacy. Defaults to 1e-5.}

\item{max_grad_norm}{Maximum gradient norm for per-sample gradient clipping.
Bounds the sensitivity of individual gradients. Defaults to 1.0.}

\item{noise_multiplier}{Multiplier for Gaussian noise added to gradients.
If NULL (default), it will be calibrated to achieve target_epsilon over the
specified epochs. Higher values provide more privacy but reduce utility.}

\item{sampling_rate}{Expected sampling rate for Poisson subsampling. If NULL
(default), calculated as batch_size / nrow(data). Must be between 0 and 1.}

\item{batch_size}{Target batch size for training. With Poisson subsampling,
actual batch sizes will vary. Defaults to 50.}

\item{epochs}{The number of training epochs. Defaults to 50.}

\item{plot_progress}{Monitor training progress with plots. Defaults to FALSE.}

\item{plot_interval}{Number of training steps between plots. Defaults to "epoch".}

\item{eval_dropout}{Should dropout be applied during sampling? Defaults to FALSE.}

\item{synthetic_examples}{Number of synthetic examples to generate. Defaults to 500.}

\item{plot_dimensions}{Which dimensions to plot. Defaults to c(1, 2).}

\item{track_loss}{Store training losses as output. Defaults to FALSE.}

\item{device}{Device for computation ("cpu", "cuda", "mps"). Defaults to "cpu".}

\item{seed}{Optional seed for reproducibility. Defaults to NULL.}

\item{verbose}{Print privacy accounting information during training. Defaults to TRUE.}
}
\value{
A list of class "trained_RGAN" containing:
\itemize{
\item generator: The trained generator network
\item discriminator: The trained discriminator network
\item losses: Training losses if track_loss is TRUE
\item privacy: Privacy accounting information including final epsilon
\item settings: Training settings used
}
}
\description{
Provides a function to train a GAN model with differential privacy
guarantees using DP-SGD (Differentially Private Stochastic Gradient Descent).
Uses OpenDP for cryptographically secure noise generation and Poisson subsampling.
}
\details{
This function implements DP-SGD (Abadi et al., 2016) for training GANs with
formal differential privacy guarantees. Key privacy mechanisms include:

\strong{Poisson Subsampling}: Each training example is included in a batch
independently with probability q = sampling_rate, providing privacy amplification.
Uses OpenDP's cryptographically secure random number generation.

\strong{Per-Sample Gradient Clipping}: Each sample's gradient is computed
individually and clipped to bound sensitivity.

\strong{Gaussian Noise}: Calibrated Gaussian noise is added to clipped gradients
using OpenDP's secure Gaussian mechanism.

\strong{RDP Accounting}: Uses Renyi Differential Privacy for tight composition
of privacy loss across training steps.

The discriminator is trained with DP-SGD while the generator is trained normally
(since it only sees synthetic data from the discriminator's gradients).
}
\examples{
\dontrun{
# Before running, install OpenDP: install.packages("opendp")
# and torch: torch::install_torch()

# Load data
data <- sample_toydata()
transformer <- data_transformer$new()
transformer$fit(data)
transformed_data <- transformer$transform(data)

# Train with differential privacy (epsilon = 1)
trained_gan <- dp_gan_trainer(
  transformed_data,
  target_epsilon = 1.0,
  target_delta = 1e-5,
  max_grad_norm = 1.0,
  epochs = 50
)

# Check final privacy budget
print(trained_gan$privacy$final_epsilon)

# Sample synthetic data
synthetic_data <- sample_synthetic_data(trained_gan, transformer)
}
}
\references{
Abadi, M., Chu, A., Goodfellow, I., McMahan, H. B., Mironov, I., Talwar, K., & Zhang, L. (2016).
Deep learning with differential privacy. In Proceedings of the 2016 ACM SIGSAC conference
on computer and communications security (pp. 308-318).

Mironov, I. (2017). Renyi differential privacy. In 2017 IEEE 30th computer security
foundations symposium (CSF) (pp. 263-275).
}
