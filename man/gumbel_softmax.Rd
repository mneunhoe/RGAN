% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/utility-functions.R
\name{gumbel_softmax}
\alias{gumbel_softmax}
\title{Gumbel-Softmax Sampling}
\usage{
gumbel_softmax(logits, tau = 1, hard = FALSE, dim = -1)
}
\arguments{
\item{logits}{A torch tensor of unnormalized log probabilities}

\item{tau}{Temperature parameter. Lower values make the distribution more discrete.
Defaults to 1.0.}

\item{hard}{If TRUE, returns hard one-hot samples but gradients are computed as if
soft samples were used (straight-through estimator). Defaults to FALSE.}

\item{dim}{The dimension along which to apply softmax. Defaults to -1 (last dimension).}
}
\value{
A torch tensor of the same shape as logits, containing either soft or hard samples
}
\description{
Implements the Gumbel-Softmax (Concrete) distribution for differentiable
sampling from categorical distributions. During training, returns soft samples that
allow gradients to flow. During inference, can return hard one-hot samples.
}
\examples{
\dontrun{
logits <- torch::torch_randn(c(10, 5))  # 10 samples, 5 categories
soft_samples <- gumbel_softmax(logits, tau = 0.5)
hard_samples <- gumbel_softmax(logits, tau = 0.5, hard = TRUE)
}
}
